{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== init ========\n",
      "===== load mnist =====\n",
      "init done.\n",
      "=== training done ====\n",
      "5 5\n",
      "6 0\n",
      "2 4\n",
      "0 1\n",
      "7 9\n",
      "5 2\n",
      "6 1\n",
      "9 3\n",
      "3 1\n",
      "4 4\n",
      "3 3\n",
      "4 5\n",
      "1 3\n",
      "8 6\n",
      "5 1\n",
      "3 7\n",
      "7 2\n",
      "7 8\n",
      "8 6\n",
      "9 9\n",
      "1 4\n",
      "6 0\n",
      "4 9\n",
      "8 1\n",
      "6 1\n",
      "7 2\n",
      "4 4\n",
      "9 3\n",
      "3 2\n",
      "6 7\n",
      "===== test done ======\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.unicode'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "       '\\\\usepackage{CJK}',\n",
    "       r'\\AtBeginDocument{\\begin{CJK}{UTF8}{gbsn}}',\n",
    "       r'\\AtEndDocument{\\end{CJK}}',\n",
    "]\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import struct\n",
    "#pl.style.use('ggplot')\n",
    "\n",
    "# 1. neuron activation is probalistic.\n",
    "# 2. sample learning is proactive.\n",
    "# 3. unsupervised learning leads to reference learning(*)\n",
    "# 4. small labeled data works too.\n",
    "# 5. self-organizing map group\n",
    "# 6. association(*)\n",
    "\n",
    "# [NOTICE] to realize (3) and (6), we deal with this:\n",
    "# (1) A compainied activation grows a strong connection\n",
    "# (2) A decay ratio for strength of existing connections\n",
    "# (3) It's not a end-to-end system>>> it's side-by-side\n",
    "#     Input A and Output B all viewed as input signals\n",
    "#     Output B connected to a hidden layer of net extending from A\n",
    "\n",
    "# Proactive Probalistic Reference Net\n",
    "\n",
    "# neural network is being constructed beyond layer based architecture\n",
    "# neurons are arranged in a form of organization\n",
    "\n",
    "def response_replaced(x, w):\n",
    "    return np.dot(x,w)/(np.sqrt(np.dot(x,x))*np.sqrt(np.dot(w,w)))\n",
    "def response(x, w):\n",
    "    return 1.0 - np.max(np.abs(x-w))\n",
    "\n",
    "def load_mnist(im_path, lb_path):\n",
    "    # loading images\n",
    "    binfile = open(im_path, 'rb')\n",
    "    buf = binfile.read()\n",
    "    index = 0\n",
    "    magic,numImages,numRows,numColumns = \\\n",
    "    struct.unpack_from('>IIII' , buf , index)\n",
    "    index += struct.calcsize('>IIII')\n",
    "    if magic!=2051:\n",
    "        raise NameError('MNIST TRAIN-IMAGE INCCORECT!')\n",
    "    ims = np.zeros([numImages, numRows*numColumns])\n",
    "    for i in range(numImages):\n",
    "        ims[i,:] = struct.unpack_from('>784B', buf, index)\n",
    "        index += struct.calcsize('>784B');\n",
    "    # loading labels\n",
    "    binfile = open(lb_path, 'rb')\n",
    "    buf = binfile.read()\n",
    "    index = 0\n",
    "    magic,numLabels = struct.unpack_from(\n",
    "        '>II', \n",
    "        buf, \n",
    "        index\n",
    "    )\n",
    "    index += struct.calcsize('>II')\n",
    "    if magic!=2049:\n",
    "        raise NameError('MNIST TRAIN-LABEL INCORRECT!')\n",
    "    lbs = np.zeros(numLabels)\n",
    "    lbs[:] = struct.unpack_from(\n",
    "        '>'+ str(numLabels) +'B', \n",
    "        buf, \n",
    "        index\n",
    "    )\n",
    "    return [ims, numRows, numColumns, lbs]\n",
    "\n",
    "\n",
    "class PPRN:\n",
    "    '''\n",
    "    eta : learning rate for Probalistic Proactive Reference Net\n",
    "    dim : neural network dimension\n",
    "    hid : hidden layers\n",
    "    som : parameters, self organizing map\n",
    "    '''\n",
    "    eta = 0\n",
    "    dim = []\n",
    "    hid = []\n",
    "    som = []\n",
    "    \n",
    "    def init(self, dim, eta):\n",
    "        '''\n",
    "        initial for the class\n",
    "        dim : the dimension for PPRN\n",
    "        eta : the learning rate\n",
    "        '''\n",
    "        self.eta = eta\n",
    "        self.dim = dim\n",
    "        self.hid = list(range(dim.shape[0]))\n",
    "        self.som = list(range(dim.shape[0]))\n",
    "        \n",
    "        for i in range(dim.shape[0]):\n",
    "            self.hid[i] = np.zeros([self.dim[i,0], self.dim[i,1]])\n",
    "            self.som[i] = np.random.rand(self.dim[i, 0], self.dim[i, 1], self.dim[i, 2])\n",
    "        print 'init done.'\n",
    "        \n",
    "    def train(self, x):\n",
    "        '''\n",
    "        training net with unlabeled data of [x]\n",
    "        '''\n",
    "        for i in range(self.dim.shape[0]):\n",
    "            for j in range(self.dim[i,0]):\n",
    "                for k in range(self.dim[i,1]):\n",
    "                    if i==0:\n",
    "                        self.hid[i][j,k] = response(x, self.som[i][j,k,:])\n",
    "                    else:\n",
    "                        self.hid[i][j,k] = response(self.hid[i-1][:,0], self.som[i][j,k,:])\n",
    "                m = np.max(self.hid[i][j,:])\n",
    "                if m > np.random.rand(1): # probalistic activation\n",
    "                    # update all patterns in som according to its response value\n",
    "                    if i == 0:\n",
    "                        for k in range(self.dim[i,1]):\n",
    "                            self.som[i][j,k,:] += \\\n",
    "                            self.eta*(self.hid[i][j,k]/m)*(x-self.som[i][j,k,:])\n",
    "                    else:\n",
    "                        for k in range(self.dim[i,1]):\n",
    "                            self.som[i][j,k,:] += self.eta*(self.hid[i][j,k]/m)*\\\n",
    "                            (self.hid[i-1][:,0]-self.som[i][j,k,:])\n",
    "                    # store the maximum value on first element as hidden activation\n",
    "                self.hid[i][j,0] = m\n",
    "                    \n",
    "    def test(self, x):\n",
    "        self.train(x)\n",
    "        return np.argmax(self.hid[self.dim.shape[0]-1][:,0])\n",
    "\n",
    "def main():\n",
    "    print '======== init ========'\n",
    "    net = PPRN()\n",
    "    # reading MINST database\n",
    "    # load training images\n",
    "    train_im_path = '../MNIST/train-images-idx3-ubyte'\n",
    "    train_lb_path = '../MNIST/train-labels-idx1-ubyte'\n",
    "    test_im_path = '../MNIST/t10k-images-idx3-ubyte'\n",
    "    test_lb_path = '../MNIST/t10k-labels-idx1-ubyte'\n",
    "    # prepare data for training and testing\n",
    "    print '===== load mnist ====='\n",
    "    [ims_train, h, w, lbs_train] = load_mnist(train_im_path, train_lb_path)\n",
    "    train_num = ims_train.shape[0]\n",
    "    numlbl = 10\n",
    "    # load test mnist data\n",
    "    [ims_test, h, w, lbs_test] = load_mnist(test_im_path, test_lb_path)\n",
    "    test_num = ims_test.shape[0]\n",
    "    # apply a dataset\n",
    "    net.init(np.array([[numlbl, 32, h*w]]), 0.1)\n",
    "    for i in range(100000):\n",
    "        net.train(ims_train[i%100,:]/255.0)\n",
    "    print '=== training done ===='\n",
    "    # test the model\n",
    "    for i in range(30):\n",
    "        print net.test(ims_train[i,:]/255.0), int(lbs_train[i])\n",
    "    print '===== test done ======'\n",
    "    \n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
