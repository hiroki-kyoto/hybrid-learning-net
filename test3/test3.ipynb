{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== init ========\n",
      "===== load mnist =====\n",
      "init done.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.unicode'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = [\n",
    "       '\\\\usepackage{CJK}',\n",
    "       r'\\AtBeginDocument{\\begin{CJK}{UTF8}{gbsn}}',\n",
    "       r'\\AtEndDocument{\\end{CJK}}',\n",
    "]\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import struct\n",
    "#pl.style.use('ggplot')\n",
    "\n",
    "# 1. neuron activation is probalistic.\n",
    "# 2. sample learning is proactive.\n",
    "# 3. unsupervised learning leads to reference learning(*)\n",
    "# 4. small labeled data works too.\n",
    "# 5. self-organizing map group\n",
    "# 6. association(*)\n",
    "\n",
    "# [NOTICE] to realize (3) and (6), we deal with this:\n",
    "# (1) A compainied activation grows a strong connection\n",
    "# (2) A decay ratio for strength of existing connections\n",
    "# (3) It's not a end-to-end system>>> it's side-by-side\n",
    "#     Input A and Output B all viewed as input signals\n",
    "#     Output B connected to a hidden layer of net extending from A\n",
    "\n",
    "\n",
    "# Proactive Probalistic Reference Net\n",
    "\n",
    "# neural network is being constructed beyond layer based architecture\n",
    "# neurons are arranged in a form of organization\n",
    "\n",
    "def response_replaced(x, w):\n",
    "    return np.dot(x,w)/(np.sqrt(np.dot(x,x))*np.sqrt(np.dot(w,w)))\n",
    "def response(x, w):\n",
    "    return 1.0 - np.max(np.abs(x-w))\n",
    "\n",
    "def load_mnist(im_path, lb_path):\n",
    "    # loading images\n",
    "    binfile = open(im_path, 'rb')\n",
    "    buf = binfile.read()\n",
    "    index = 0\n",
    "    magic,numImages,numRows,numColumns = \\\n",
    "    struct.unpack_from('>IIII' , buf , index)\n",
    "    index += struct.calcsize('>IIII')\n",
    "    if magic!=2051:\n",
    "        raise NameError('MNIST TRAIN-IMAGE INCCORECT!')\n",
    "    ims = np.zeros([numImages, numRows*numColumns])\n",
    "    for i in range(numImages):\n",
    "        ims[i,:] = struct.unpack_from('>784B', buf, index)\n",
    "        index += struct.calcsize('>784B');\n",
    "    # loading labels\n",
    "    binfile = open(lb_path, 'rb')\n",
    "    buf = binfile.read()\n",
    "    index = 0\n",
    "    magic,numLabels = struct.unpack_from(\n",
    "        '>II', \n",
    "        buf, \n",
    "        index\n",
    "    )\n",
    "    index += struct.calcsize('>II')\n",
    "    if magic!=2049:\n",
    "        raise NameError('MNIST TRAIN-LABEL INCORRECT!')\n",
    "    lbs = np.zeros(numLabels)\n",
    "    lbs[:] = struct.unpack_from(\n",
    "        '>'+ str(numLabels) +'B', \n",
    "        buf, \n",
    "        index\n",
    "    )\n",
    "    return [ims, numRows, numColumns, lbs]\n",
    "\n",
    "\n",
    "class PPRN:\n",
    "    eta = 0\n",
    "    in_dim = []\n",
    "    out_dim = []\n",
    "    hid_dep = 0\n",
    "    hid_dim = []\n",
    "    som_dim = []\n",
    "    hid = []\n",
    "    som = []\n",
    "    def init(self, in_dim, out_dim, hid_dep, eta):\n",
    "        self.eta = eta\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dep = hid_dep\n",
    "        self.hid_dim = np.zeros(hid_dep, dtype=np.int)\n",
    "        self.som_dim = np.zeros([hid_dep, 3], dtype=np.int)\n",
    "        self.hid = list(range(hid_dep))\n",
    "        self.som = list(range(hid_dep))\n",
    "        times = 1\n",
    "        init_hid_dim = 2**hid_dep\n",
    "        for i in range(hid_dep): \n",
    "            times = times * 2\n",
    "            self.hid_dim[i] = times * self.in_dim\n",
    "            self.som_dim[i, :] = [self.hid_dim[i], init_hid_dim/times, self.hid_dim[i]/2]\n",
    "            self.hid[i] = np.zeros([self.som_dim[i,0], self.som_dim[i,1]])\n",
    "            self.som[i] = np.random.rand(self.som_dim[i, 0], self.som_dim[i, 1], self.som_dim[i, 2])\n",
    "        print 'init done.'\n",
    "    # 1. layer by layer training\n",
    "    # 2. probalistic activation\n",
    "    # 3. selective learning for the supervised learning\n",
    "    def train(self, x, y):\n",
    "        for i in range(self.hid_dep):\n",
    "            for j in range(self.som_dim[i,0]):\n",
    "                for k in range(self.som_dim[i,1]):\n",
    "                    if i==0:\n",
    "                        self.hid[i][j,k] = response(x, self.som[i][j,k,:])\n",
    "                    else:\n",
    "                        self.hid[i][j,k] = response(self.hid[i-1][:,0], self.som[i][j,k,:])\n",
    "                m = np.max(self.hid[i][j,:])\n",
    "                if m > np.random.rand(1): # probalistic activation\n",
    "                    # update all patterns in som according to its response value\n",
    "                    if i == 0:\n",
    "                        for k in range(self.som_dim[i,1]):\n",
    "                            self.som[i][j,k,:] += \\\n",
    "                            self.eta*(self.hid[i][j,k]/m)*(x-self.som[i][j,k,:])\n",
    "                    else:\n",
    "                        for k in range(self.som_dim[i,1]):\n",
    "                            self.som[i][j,k,:] += self.eta*(self.hid[i][j,k]/m)*\\\n",
    "                            (self.hid[i-1][:,0]-self.som[i][j,k,:])\n",
    "                    # store the maximum value on first element as hidden activation\n",
    "                    self.hid[i][j,0] = m\n",
    "                else:\n",
    "                    # store the maximum value on first element as hidden activation\n",
    "                    self.hid[i][j,0] = 0\n",
    "\n",
    "def main():\n",
    "    print '======== init ========'\n",
    "    net = PPRN()\n",
    "    # reading MINST database\n",
    "    # load training images\n",
    "    train_im_path = '../MNIST/train-images-idx3-ubyte'\n",
    "    train_lb_path = '../MNIST/train-labels-idx1-ubyte'\n",
    "    test_im_path = '../MNIST/t10k-images-idx3-ubyte'\n",
    "    test_lb_path = '../MNIST/t10k-labels-idx1-ubyte'\n",
    "    # prepare data for training and testing\n",
    "    print '===== load mnist ====='\n",
    "    [ims_train, h, w, lbs] = load_mnist(train_im_path, train_lb_path)\n",
    "    train_num = ims_train.shape[0]\n",
    "    numlbl = 10\n",
    "    # load test mnist data\n",
    "    [ims_test, h, w, lbs_test] = load_mnist(test_im_path, test_lb_path)\n",
    "    test_num = ims_test.shape[0]\n",
    "    # apply a dataset\n",
    "    net.init(h*w, numlbl, 3, 0.1)\n",
    "    for i in range(train_num):\n",
    "        net.train(ims_train[i,:], [])\n",
    "    print '=== procedure done ==='\n",
    "    \n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
